{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt install python3.10-venv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAKBilpMLpWh",
        "outputId": "d903dc44-75c8-4d1c-98fb-d5a37d6a9bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 2,473 kB of archives.\n",
            "After this operation, 2,884 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.4 [1,680 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.1 [788 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.5 [5,724 B]\n",
            "Fetched 2,473 kB in 2s (1,419 kB/s)\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 123597 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.5_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.5) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.5) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m venv venv\n",
        "!source venv/bin/activate"
      ],
      "metadata": {
        "id": "Z9IMhyQhLeYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UWAGA!\n",
        "Teraz należy uruchomić panel boczny i ręcznie zmodyfikować plik venv/bin/activate poprzez wklejenie poniższych informacji:\n",
        "\n",
        "```\n",
        "export NIAH_MODEL_API_KEY=\"\" # Tutaj wprowadź hugginface api key\n",
        "export NIAH_EVALUATOR_API_KEY=\"\"  # tutaj wprowadź openAI api key\n",
        "export HF_HOME=/content/cache/\n",
        "```"
      ],
      "metadata": {
        "id": "MD1Chdgj_7gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LazyDart/LLMTest_NeedleInAHaystack.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhXaF6p4MroO",
        "outputId": "cefb93a4-6cd1-4368-f09e-ac63ff4d9592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLMTest_NeedleInAHaystack'...\n",
            "remote: Enumerating objects: 1870, done.\u001b[K\n",
            "remote: Counting objects: 100% (357/357), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 1870 (delta 301), reused 257 (delta 252), pack-reused 1513 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1870/1870), 3.92 MiB | 2.52 MiB/s, done.\n",
            "Resolving deltas: 100% (1518/1518), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source venv/bin/activate\n",
        "pip install torch torchvision torchaudio --trusted-host download.pytorch.org --index-url https://download.pytorch.org/whl/cu121 --no-cache-dir\n",
        "pip install auto-gptq --no-build-isolation\n",
        "pip install -e ./LLMTest_NeedleInAHaystack\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2dXOhd9LvJF",
        "outputId": "7993abfb-4c6e-44cc-f353-2adac8540c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (799.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 799.1/799.1 MB 45.5 MB/s eta 0:00:00\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.1/7.1 MB 47.7 MB/s eta 0:00:00\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 32.4 MB/s eta 0:00:00\n",
            "Collecting nvidia-curand-cu12==10.3.2.106\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 134.9 MB/s eta 0:00:00\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 KB 248.2 MB/s eta 0:00:00\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 95.4 MB/s eta 0:00:00\n",
            "Collecting triton==3.0.0\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.4/209.4 MB 48.4 MB/s eta 0:00:00\n",
            "Collecting filelock\n",
            "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Collecting typing-extensions>=4.8.0\n",
            "  Downloading https://download.pytorch.org/whl/typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting sympy\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 46.6 MB/s eta 0:00:00\n",
            "Collecting nvidia-nccl-cu12==2.20.5\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.2/176.2 MB 225.7 MB/s eta 0:00:00\n",
            "Collecting jinja2\n",
            "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.2/133.2 KB 88.8 MB/s eta 0:00:00\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 50.9 MB/s eta 0:00:00\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 51.1 MB/s eta 0:00:00\n",
            "Collecting networkx\n",
            "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 37.2 MB/s eta 0:00:00\n",
            "Collecting fsspec\n",
            "  Downloading https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.9/170.9 KB 297.7 MB/s eta 0:00:00\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 149.5 MB/s eta 0:00:00\n",
            "Collecting nvidia-nvtx-cu12==12.1.105\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.1/99.1 KB 255.3 MB/s eta 0:00:00\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 205.9 MB/s eta 0:00:00\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 46.1 MB/s eta 0:00:00\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 244.6 MB/s eta 0:00:00\n",
            "Collecting nvidia-nvjitlink-cu12\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.8/19.8 MB 161.8 MB/s eta 0:00:00\n",
            "Collecting numpy\n",
            "  Downloading https://download.pytorch.org/whl/numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 49.3 MB/s eta 0:00:00\n",
            "Collecting pillow!=8.3.*,>=5.3.0\n",
            "  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 43.5 MB/s eta 0:00:00\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 KB 216.4 MB/s eta 0:00:00\n",
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.2.0 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.1.105 nvidia-nvtx-cu12-12.1.105 pillow-10.2.0 sympy-1.12 torch-2.4.0+cu121 torchaudio-2.4.0+cu121 torchvision-0.19.0+cu121 triton-3.0.0 typing-extensions-4.9.0\n",
            "Collecting auto-gptq\n",
            "  Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.5/23.5 MB 69.6 MB/s eta 0:00:00\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting safetensors\n",
            "  Downloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 435.5/435.5 KB 46.8 MB/s eta 0:00:00\n",
            "Collecting gekko\n",
            "  Downloading gekko-1.2.1-py3-none-any.whl (13.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.2/13.2 MB 98.7 MB/s eta 0:00:00\n",
            "Collecting peft>=0.5.0\n",
            "  Downloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 296.4/296.4 KB 38.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from auto-gptq) (1.26.3)\n",
            "Collecting transformers>=4.31.0\n",
            "  Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.5/9.5 MB 119.7 MB/s eta 0:00:00\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.4/78.4 KB 12.3 MB/s eta 0:00:00\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 83.2 MB/s eta 0:00:00\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 527.3/527.3 KB 53.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: torch>=1.13.0 in ./venv/lib/python3.10/site-packages (from auto-gptq) (2.4.0+cu121)\n",
            "Collecting accelerate>=0.26.0\n",
            "  Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 315.1/315.1 KB 41.2 MB/s eta 0:00:00\n",
            "Collecting packaging>=20.0\n",
            "  Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.0/54.0 KB 8.0 MB/s eta 0:00:00\n",
            "Collecting huggingface-hub>=0.21.0\n",
            "  Downloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 417.5/417.5 KB 48.2 MB/s eta 0:00:00\n",
            "Collecting psutil\n",
            "  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 290.5/290.5 KB 37.3 MB/s eta 0:00:00\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 751.2/751.2 KB 64.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.3.1)\n",
            "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2024.2.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\n",
            "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.1.3)\n",
            "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.13.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2.20.5)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.0.106)\n",
            "Requirement already satisfied: triton==3.0.0 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.0.0)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\n",
            "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (4.9.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->auto-gptq) (12.1.105)\n",
            "Collecting requests\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.9/64.9 KB 11.1 MB/s eta 0:00:00\n",
            "Collecting tokenizers<0.20,>=0.19\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 101.0 MB/s eta 0:00:00\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 776.5/776.5 KB 2.1 MB/s eta 0:00:00\n",
            "Collecting pyarrow>=15.0.0\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.9/39.9 MB 41.8 MB/s eta 0:00:00\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.8/134.8 KB 16.8 MB/s eta 0:00:00\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.0/13.0 MB 111.0 MB/s eta 0:00:00\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 80.7 MB/s eta 0:00:00\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 KB 23.5 MB/s eta 0:00:00\n",
            "Collecting dill<0.3.9,>=0.3.0\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.3/116.3 KB 17.7 MB/s eta 0:00:00\n",
            "Collecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0\n",
            "  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.3/124.3 KB 19.9 MB/s eta 0:00:00\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.0/63.0 KB 9.0 MB/s eta 0:00:00\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (304 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 305.0/305.0 KB 37.4 MB/s eta 0:00:00\n",
            "Collecting async-timeout<5.0,>=4.0\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 239.5/239.5 KB 32.8 MB/s eta 0:00:00\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.8-py3-none-any.whl (66 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.9/66.9 KB 10.2 MB/s eta 0:00:00\n",
            "Collecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.4/121.4 KB 20.8 MB/s eta 0:00:00\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.1/142.1 KB 22.3 MB/s eta 0:00:00\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.3/167.3 KB 25.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.5)\n",
            "Collecting tzdata>=2022.7\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 345.4/345.4 KB 45.5 MB/s eta 0:00:00\n",
            "Collecting python-dateutil>=2.8.2\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 KB 28.9 MB/s eta 0:00:00\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 505.5/505.5 KB 52.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n",
            "Installing collected packages: sentencepiece, pytz, xxhash, urllib3, tzdata, tqdm, six, safetensors, regex, pyyaml, pyarrow, psutil, packaging, multidict, idna, gekko, frozenlist, dill, charset-normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, rouge, requests, python-dateutil, multiprocess, aiosignal, pandas, huggingface-hub, aiohttp, tokenizers, accelerate, transformers, datasets, peft, auto-gptq\n",
            "Successfully installed accelerate-0.33.0 aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-24.2.0 auto-gptq-0.7.1 certifi-2024.8.30 charset-normalizer-3.3.2 datasets-2.21.0 dill-0.3.8 frozenlist-1.4.1 gekko-1.2.1 huggingface-hub-0.24.6 idna-3.8 multidict-6.0.5 multiprocess-0.70.16 packaging-24.1 pandas-2.2.2 peft-0.12.0 psutil-6.0.0 pyarrow-17.0.0 python-dateutil-2.9.0.post0 pytz-2024.1 pyyaml-6.0.2 regex-2024.7.24 requests-2.32.3 rouge-1.0.1 safetensors-0.4.4 sentencepiece-0.2.0 six-1.16.0 tokenizers-0.19.1 tqdm-4.66.5 transformers-4.44.2 tzdata-2024.1 urllib3-2.2.2 xxhash-3.5.0 yarl-1.9.6\n",
            "Obtaining file:///content/LLMTest_NeedleInAHaystack\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting PyYAML==6.0.1\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 705.5/705.5 KB 15.9 MB/s eta 0:00:00\n",
            "Collecting SQLAlchemy==2.0.23\n",
            "  Downloading SQLAlchemy-2.0.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 73.2 MB/s eta 0:00:00\n",
            "Collecting aiohttp==3.9.1\n",
            "  Downloading aiohttp-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 2.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: aiosignal==1.3.1 in ./venv/lib/python3.10/site-packages (from needlehaystack==0.1.0) (1.3.1)\n",
            "Collecting annotated-types==0.6.0\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting anthropic>=0.7.5\n",
            "  Downloading anthropic-0.34.1-py3-none-any.whl (891 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 891.5/891.5 KB 66.0 MB/s eta 0:00:00\n",
            "Collecting anyio==3.7.1\n",
            "  Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.9/80.9 KB 11.7 MB/s eta 0:00:00\n",
            "Collecting attrs==23.1.0\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 KB 8.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: auto-gptq in ./venv/lib/python3.10/site-packages (from needlehaystack==0.1.0) (0.7.1)\n",
            "Collecting certifi==2023.11.17\n",
            "  Downloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 162.5/162.5 KB 25.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in ./venv/lib/python3.10/site-packages (from needlehaystack==0.1.0) (3.3.2)\n",
            "Collecting dataclasses-json==0.6.3\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting distro==1.8.0\n",
            "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: filelock==3.13.1 in ./venv/lib/python3.10/site-packages (from needlehaystack==0.1.0) (3.13.1)\n",
            "Collecting frozenlist==1.4.0\n",
            "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 225.7/225.7 KB 29.9 MB/s eta 0:00:00\n",
            "Collecting fsspec==2023.10.0\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 166.4/166.4 KB 24.3 MB/s eta 0:00:00\n",
            "Collecting h11==0.14.0\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 KB 8.5 MB/s eta 0:00:00\n",
            "Collecting httpcore==1.0.2\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.9/76.9 KB 13.2 MB/s eta 0:00:00\n",
            "Collecting httpx==0.25.2\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.0/75.0 KB 11.4 MB/s eta 0:00:00\n",
            "Collecting huggingface-hub==0.24.1\n",
            "  Downloading huggingface_hub-0.24.1-py3-none-any.whl (417 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 417.2/417.2 KB 48.8 MB/s eta 0:00:00\n",
            "Collecting idna==3.6\n",
            "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.6/61.6 KB 9.5 MB/s eta 0:00:00\n",
            "Collecting jsonargparse==4.27.5\n",
            "  Downloading jsonargparse-4.27.5-py3-none-any.whl (191 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 191.3/191.3 KB 27.3 MB/s eta 0:00:00\n",
            "Collecting jsonpatch==1.33\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting jsonpointer==2.4\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting langchain-community>=0.0.24\n",
            "  Downloading langchain_community-0.2.15-py3-none-any.whl (2.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 94.9 MB/s eta 0:00:00\n",
            "Collecting langchain-core==0.1.26\n",
            "  Downloading langchain_core-0.1.26-py3-none-any.whl (246 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 246.4/246.4 KB 33.3 MB/s eta 0:00:00\n",
            "Collecting langchain==0.1.9\n",
            "  Downloading langchain-0.1.9-py3-none-any.whl (816 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 817.0/817.0 KB 53.6 MB/s eta 0:00:00\n",
            "Collecting langchain_anthropic\n",
            "  Downloading langchain_anthropic-0.1.23-py3-none-any.whl (21 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.23-py3-none-any.whl (51 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.0/52.0 KB 8.4 MB/s eta 0:00:00\n",
            "Collecting langsmith>=0.1.8\n",
            "  Downloading langsmith-0.1.108-py3-none-any.whl (150 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 150.7/150.7 KB 21.8 MB/s eta 0:00:00\n",
            "Collecting marshmallow==3.20.1\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.4/49.4 KB 7.4 MB/s eta 0:00:00\n",
            "Collecting multidict==6.0.4\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 KB 14.6 MB/s eta 0:00:00\n",
            "Collecting mypy-extensions==1.0.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting numpy==1.26.2\n",
            "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 84.7 MB/s eta 0:00:00\n",
            "Collecting openai>=1.3.5\n",
            "  Downloading openai-1.43.0-py3-none-any.whl (365 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 365.7/365.7 KB 41.7 MB/s eta 0:00:00\n",
            "Collecting optimum\n",
            "  Downloading optimum-1.21.4-py3-none-any.whl (421 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 421.5/421.5 KB 49.5 MB/s eta 0:00:00\n",
            "Collecting packaging==23.2\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 KB 7.2 MB/s eta 0:00:00\n",
            "Collecting pydantic==2.5.2\n",
            "  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 381.9/381.9 KB 45.2 MB/s eta 0:00:00\n",
            "Collecting pydantic_core==2.14.5\n",
            "  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 86.0 MB/s eta 0:00:00\n",
            "Collecting pytest==8.1.1\n",
            "  Downloading pytest-8.1.1-py3-none-any.whl (337 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 337.4/337.4 KB 41.2 MB/s eta 0:00:00\n",
            "Collecting python-dotenv==1.0.0\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting regex==2023.10.3\n",
            "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 773.9/773.9 KB 59.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: requests==2.32.3 in ./venv/lib/python3.10/site-packages (from needlehaystack==0.1.0) (2.32.3)\n",
            "Collecting sniffio==1.3.0\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting tenacity==8.2.3\n",
            "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Collecting tiktoken>=0.5.1\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 82.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tokenizers==0.19.1 in ./venv/lib/python3.10/site-packages (from needlehaystack==0.1.0) (0.19.1)\n",
            "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (from needlehaystack==0.1.0) (2.4.0+cu121)\n",
            "Collecting tqdm==4.66.4\n",
            "  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.3/78.3 KB 11.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (from needlehaystack==0.1.0) (4.44.2)\n",
            "Collecting typing-inspect==0.9.0\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting typing_extensions==4.8.0\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Collecting urllib3==2.1.0\n",
            "  Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 104.6/104.6 KB 14.5 MB/s eta 0:00:00\n",
            "Collecting yarl==1.9.3\n",
            "  Downloading yarl-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.7/300.7 KB 39.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv/lib/python3.10/site-packages (from aiohttp==3.9.1->needlehaystack==0.1.0) (4.0.3)\n",
            "Collecting exceptiongroup\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Collecting langchain-community>=0.0.24\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 93.4 MB/s eta 0:00:00\n",
            "Collecting iniconfig\n",
            "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
            "Collecting tomli>=1\n",
            "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting pluggy<2.0,>=1.4\n",
            "  Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
            "Collecting greenlet!=0.4.17\n",
            "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 616.0/616.0 KB 63.2 MB/s eta 0:00:00\n",
            "Collecting jiter<1,>=0.4.0\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 318.9/318.9 KB 40.4 MB/s eta 0:00:00\n",
            "Collecting langchain-community>=0.0.24\n",
            "  Downloading langchain_community-0.0.37-py3-none-any.whl (2.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 85.5 MB/s eta 0:00:00\n",
            "  Downloading langchain_community-0.0.36-py3-none-any.whl (2.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 74.3 MB/s eta 0:00:00\n",
            "  Downloading langchain_community-0.0.35-py3-none-any.whl (2.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 93.8 MB/s eta 0:00:00\n",
            "  Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 97.1 MB/s eta 0:00:00\n",
            "  Downloading langchain_community-0.0.33-py3-none-any.whl (1.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 91.4 MB/s eta 0:00:00\n",
            "  Downloading langchain_community-0.0.32-py3-none-any.whl (1.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 86.8 MB/s eta 0:00:00\n",
            "  Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 87.8 MB/s eta 0:00:00\n",
            "  Downloading langchain_community-0.0.30-py3-none-any.whl (1.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 95.8 MB/s eta 0:00:00\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 92.4 MB/s eta 0:00:00\n",
            "  Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 81.6 MB/s eta 0:00:00\n",
            "  Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 54.8 MB/s eta 0:00:00\n",
            "  Downloading langchain_community-0.0.26-py3-none-any.whl (1.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 74.6 MB/s eta 0:00:00\n",
            "  Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 87.9 MB/s eta 0:00:00\n",
            "  Downloading langchain_community-0.0.24-py3-none-any.whl (1.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 68.3 MB/s eta 0:00:00\n",
            "Collecting orjson<4.0.0,>=3.9.14\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.9/141.9 KB 20.5 MB/s eta 0:00:00\n",
            "Collecting openai>=1.3.5\n",
            "  Downloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 362.9/362.9 KB 44.3 MB/s eta 0:00:00\n",
            "  Downloading openai-1.41.1-py3-none-any.whl (362 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 362.5/362.5 KB 45.2 MB/s eta 0:00:00\n",
            "  Downloading openai-1.41.0-py3-none-any.whl (362 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 362.4/362.4 KB 46.0 MB/s eta 0:00:00\n",
            "  Downloading openai-1.40.8-py3-none-any.whl (361 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 361.5/361.5 KB 43.4 MB/s eta 0:00:00\n",
            "  Downloading openai-1.40.7-py3-none-any.whl (361 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 361.2/361.2 KB 45.0 MB/s eta 0:00:00\n",
            "  Downloading openai-1.40.6-py3-none-any.whl (361 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 361.3/361.3 KB 47.5 MB/s eta 0:00:00\n",
            "  Downloading openai-1.40.5-py3-none-any.whl (361 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 361.3/361.3 KB 47.7 MB/s eta 0:00:00\n",
            "  Downloading openai-1.40.4-py3-none-any.whl (361 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 361.3/361.3 KB 48.5 MB/s eta 0:00:00\n",
            "  Downloading openai-1.40.3-py3-none-any.whl (360 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 360.7/360.7 KB 48.4 MB/s eta 0:00:00\n",
            "  Downloading openai-1.40.2-py3-none-any.whl (360 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 360.7/360.7 KB 47.9 MB/s eta 0:00:00\n",
            "  Downloading openai-1.40.1-py3-none-any.whl (360 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 360.4/360.4 KB 45.0 MB/s eta 0:00:00\n",
            "  Downloading openai-1.40.0-py3-none-any.whl (360 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 360.4/360.4 KB 45.3 MB/s eta 0:00:00\n",
            "  Downloading openai-1.39.0-py3-none-any.whl (336 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 336.7/336.7 KB 41.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: gekko in ./venv/lib/python3.10/site-packages (from auto-gptq->needlehaystack==0.1.0) (1.2.1)\n",
            "Requirement already satisfied: peft>=0.5.0 in ./venv/lib/python3.10/site-packages (from auto-gptq->needlehaystack==0.1.0) (0.12.0)\n",
            "Requirement already satisfied: sentencepiece in ./venv/lib/python3.10/site-packages (from auto-gptq->needlehaystack==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in ./venv/lib/python3.10/site-packages (from auto-gptq->needlehaystack==0.1.0) (0.33.0)\n",
            "Requirement already satisfied: rouge in ./venv/lib/python3.10/site-packages (from auto-gptq->needlehaystack==0.1.0) (1.0.1)\n",
            "Requirement already satisfied: safetensors in ./venv/lib/python3.10/site-packages (from auto-gptq->needlehaystack==0.1.0) (0.4.4)\n",
            "Requirement already satisfied: datasets in ./venv/lib/python3.10/site-packages (from auto-gptq->needlehaystack==0.1.0) (2.21.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (1.12)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (3.2.1)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch->needlehaystack==0.1.0) (3.1.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->needlehaystack==0.1.0) (12.1.105)\n",
            "Collecting defusedxml<0.8.0,>=0.7.1\n",
            "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Collecting langchain_anthropic\n",
            "  Downloading langchain_anthropic-0.1.22-py3-none-any.whl (20 kB)\n",
            "  Downloading langchain_anthropic-0.1.21-py3-none-any.whl (20 kB)\n",
            "  Downloading langchain_anthropic-0.1.20-py3-none-any.whl (20 kB)\n",
            "  Downloading langchain_anthropic-0.1.19-py3-none-any.whl (20 kB)\n",
            "  Downloading langchain_anthropic-0.1.18-py3-none-any.whl (20 kB)\n",
            "  Downloading langchain_anthropic-0.1.17-py3-none-any.whl (19 kB)\n",
            "  Downloading langchain_anthropic-0.1.16-py3-none-any.whl (19 kB)\n",
            "  Downloading langchain_anthropic-0.1.15-py3-none-any.whl (16 kB)\n",
            "  Downloading langchain_anthropic-0.1.13-py3-none-any.whl (16 kB)\n",
            "  Downloading langchain_anthropic-0.1.12-py3-none-any.whl (16 kB)\n",
            "  Downloading langchain_anthropic-0.1.11-py3-none-any.whl (16 kB)\n",
            "  Downloading langchain_anthropic-0.1.10-py3-none-any.whl (16 kB)\n",
            "  Downloading langchain_anthropic-0.1.9-py3-none-any.whl (16 kB)\n",
            "  Downloading langchain_anthropic-0.1.8-py3-none-any.whl (15 kB)\n",
            "  Downloading langchain_anthropic-0.1.7-py3-none-any.whl (15 kB)\n",
            "  Downloading langchain_anthropic-0.1.6-py3-none-any.whl (13 kB)\n",
            "  Downloading langchain_anthropic-0.1.5-py3-none-any.whl (13 kB)\n",
            "  Downloading langchain_anthropic-0.1.4-py3-none-any.whl (12 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.22-py3-none-any.whl (51 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.0/52.0 KB 7.9 MB/s eta 0:00:00\n",
            "  Downloading langchain_openai-0.1.20-py3-none-any.whl (48 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.2/48.2 KB 6.0 MB/s eta 0:00:00\n",
            "  Downloading langchain_openai-0.1.19-py3-none-any.whl (47 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.1/47.1 KB 7.1 MB/s eta 0:00:00\n",
            "  Downloading langchain_openai-0.1.17-py3-none-any.whl (46 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.7/46.7 KB 7.5 MB/s eta 0:00:00\n",
            "  Downloading langchain_openai-0.1.16-py3-none-any.whl (46 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.1/46.1 KB 7.9 MB/s eta 0:00:00\n",
            "  Downloading langchain_openai-0.1.15-py3-none-any.whl (46 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.1/46.1 KB 6.3 MB/s eta 0:00:00\n",
            "  Downloading langchain_openai-0.1.14-py3-none-any.whl (45 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.9/45.9 KB 6.8 MB/s eta 0:00:00\n",
            "  Downloading langchain_openai-0.1.13-py3-none-any.whl (45 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.9/45.9 KB 6.9 MB/s eta 0:00:00\n",
            "  Downloading langchain_openai-0.1.12-py3-none-any.whl (43 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.2/43.2 KB 7.0 MB/s eta 0:00:00\n",
            "  Downloading langchain_openai-0.1.11-py3-none-any.whl (40 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.8/40.8 KB 6.9 MB/s eta 0:00:00\n",
            "  Downloading langchain_openai-0.1.10-py3-none-any.whl (40 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.6/40.6 KB 6.0 MB/s eta 0:00:00\n",
            "  Downloading langchain_openai-0.1.9-py3-none-any.whl (40 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.3/40.3 KB 5.6 MB/s eta 0:00:00\n",
            "  Downloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
            "  Downloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\n",
            "  Downloading langchain_openai-0.1.5-py3-none-any.whl (34 kB)\n",
            "  Downloading langchain_openai-0.1.4-py3-none-any.whl (33 kB)\n",
            "  Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
            "  Downloading langchain_openai-0.1.2-py3-none-any.whl (33 kB)\n",
            "  Downloading langchain_openai-0.1.1-py3-none-any.whl (32 kB)\n",
            "  Downloading langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
            "  Downloading langchain_openai-0.0.7-py3-none-any.whl (33 kB)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 KB 6.9 MB/s eta 0:00:00\n",
            "Collecting transformers[sentencepiece]<4.44.0,>=4.29.0\n",
            "  Downloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.4/9.4 MB 113.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq->needlehaystack==0.1.0) (6.0.0)\n",
            "Collecting protobuf\n",
            "  Downloading protobuf-5.28.0-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 316.6/316.6 KB 42.1 MB/s eta 0:00:00\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 KB 12.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: multiprocess in ./venv/lib/python3.10/site-packages (from datasets->auto-gptq->needlehaystack==0.1.0) (0.70.16)\n",
            "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from datasets->auto-gptq->needlehaystack==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: xxhash in ./venv/lib/python3.10/site-packages (from datasets->auto-gptq->needlehaystack==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./venv/lib/python3.10/site-packages (from datasets->auto-gptq->needlehaystack==0.1.0) (0.3.8)\n",
            "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in ./venv/lib/python3.10/site-packages (from datasets->auto-gptq->needlehaystack==0.1.0) (2024.2.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./venv/lib/python3.10/site-packages (from datasets->auto-gptq->needlehaystack==0.1.0) (17.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch->needlehaystack==0.1.0) (2.1.5)\n",
            "Requirement already satisfied: six in ./venv/lib/python3.10/site-packages (from rouge->auto-gptq->needlehaystack==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch->needlehaystack==0.1.0) (1.3.0)\n",
            "Collecting fsspec[http]<=2024.6.1,>=2023.1.0\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 177.6/177.6 KB 25.0 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.9/176.9 KB 25.6 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 316.1/316.1 KB 39.3 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.0/172.0 KB 23.5 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2024.3.0-py3-none-any.whl (171 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 171.9/171.9 KB 26.1 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 169.0/169.0 KB 22.9 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.12.1-py3-none-any.whl (168 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.9/168.9 KB 25.0 MB/s eta 0:00:00\n",
            "  Downloading fsspec-2023.12.0-py3-none-any.whl (168 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.9/168.9 KB 26.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->datasets->auto-gptq->needlehaystack==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->datasets->auto-gptq->needlehaystack==0.1.0) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas->datasets->auto-gptq->needlehaystack==0.1.0) (2024.1)\n",
            "Installing collected packages: urllib3, typing_extensions, tqdm, tomli, tenacity, sniffio, regex, PyYAML, python-dotenv, protobuf, pluggy, packaging, orjson, numpy, mypy-extensions, multidict, jsonpointer, jiter, iniconfig, idna, humanfriendly, h11, greenlet, fsspec, frozenlist, exceptiongroup, distro, defusedxml, certifi, attrs, annotated-types, yarl, typing-inspect, SQLAlchemy, pytest, pydantic_core, marshmallow, jsonpatch, jsonargparse, httpcore, coloredlogs, anyio, tiktoken, pydantic, huggingface-hub, httpx, dataclasses-json, aiohttp, openai, langsmith, transformers, langchain-core, anthropic, langchain_openai, langchain-community, langchain_anthropic, optimum, langchain, needlehaystack\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.2\n",
            "    Uninstalling urllib3-2.2.2:\n",
            "      Successfully uninstalled urllib3-2.2.2\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.5\n",
            "    Uninstalling tqdm-4.66.5:\n",
            "      Successfully uninstalled tqdm-4.66.5\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.7.24\n",
            "    Uninstalling regex-2024.7.24:\n",
            "      Successfully uninstalled regex-2024.7.24\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.3\n",
            "    Uninstalling numpy-1.26.3:\n",
            "      Successfully uninstalled numpy-1.26.3\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.0.5\n",
            "    Uninstalling multidict-6.0.5:\n",
            "      Successfully uninstalled multidict-6.0.5\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.8\n",
            "    Uninstalling idna-3.8:\n",
            "      Successfully uninstalled idna-3.8\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.2.0\n",
            "    Uninstalling fsspec-2024.2.0:\n",
            "      Successfully uninstalled fsspec-2024.2.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.4.1\n",
            "    Uninstalling frozenlist-1.4.1:\n",
            "      Successfully uninstalled frozenlist-1.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.8.30\n",
            "    Uninstalling certifi-2024.8.30:\n",
            "      Successfully uninstalled certifi-2024.8.30\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 24.2.0\n",
            "    Uninstalling attrs-24.2.0:\n",
            "      Successfully uninstalled attrs-24.2.0\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.9.6\n",
            "    Uninstalling yarl-1.9.6:\n",
            "      Successfully uninstalled yarl-1.9.6\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.6\n",
            "    Uninstalling huggingface-hub-0.24.6:\n",
            "      Successfully uninstalled huggingface-hub-0.24.6\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.10.5\n",
            "    Uninstalling aiohttp-3.10.5:\n",
            "      Successfully uninstalled aiohttp-3.10.5\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "  Running setup.py develop for needlehaystack\n",
            "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.23 aiohttp-3.9.1 annotated-types-0.6.0 anthropic-0.34.1 anyio-3.7.1 attrs-23.1.0 certifi-2023.11.17 coloredlogs-15.0.1 dataclasses-json-0.6.3 defusedxml-0.7.1 distro-1.8.0 exceptiongroup-1.2.2 frozenlist-1.4.0 fsspec-2023.10.0 greenlet-3.0.3 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 huggingface-hub-0.24.1 humanfriendly-10.0 idna-3.6 iniconfig-2.0.0 jiter-0.5.0 jsonargparse-4.27.5 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.9 langchain-community-0.0.24 langchain-core-0.1.26 langchain_anthropic-0.1.4 langchain_openai-0.0.7 langsmith-0.1.108 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 needlehaystack-0.1.0 numpy-1.26.2 openai-1.39.0 optimum-1.21.4 orjson-3.10.7 packaging-23.2 pluggy-1.5.0 protobuf-5.28.0 pydantic-2.5.2 pydantic_core-2.14.5 pytest-8.1.1 python-dotenv-1.0.0 regex-2023.10.3 sniffio-1.3.0 tenacity-8.2.3 tiktoken-0.7.0 tomli-2.0.1 tqdm-4.66.4 transformers-4.43.4 typing-inspect-0.9.0 typing_extensions-4.8.0 urllib3-2.1.0 yarl-1.9.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Używam modelu skwantyzowanego, ale za każdym razem dostaję exllama error. Więc use_exllama=False w configu ręcznie zmieniam. Config pojawia się w folderze cache w panelu bocznym po pobraniu modelu.\n",
        "<br>\n",
        "Wyniki pojawiają się w folderze results, pojedynczy plik dla pojedynczego testu."
      ],
      "metadata": {
        "id": "ReYNdIswAcxv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6lFzOdFLYDv",
        "outputId": "110fd09c-1a3f-4255-d964-1e7c78232abe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/venv/lib/python3.10/site-packages/langchain/callbacks/__init__.py:37: LangChainDeprecationWarning: Importing this callback from langchain is deprecated. Importing it from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.callbacks import base`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /content/cache/token\n",
            "Login successful\n",
            "/content/venv/lib/python3.10/site-packages/auto_gptq/nn_modules/triton_utils/kernels.py:411: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, input, qweight, scales, qzeros, g_idx, bits, maxq):\n",
            "/content/venv/lib/python3.10/site-packages/auto_gptq/nn_modules/triton_utils/kernels.py:419: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_output):\n",
            "/content/venv/lib/python3.10/site-packages/auto_gptq/nn_modules/triton_utils/kernels.py:461: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=torch.float16)\n",
            "CUDA extension not installed.\n",
            "CUDA extension not installed.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "/content/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:4674: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  3.58it/s]\n",
            "Testing single-needle\n",
            "\n",
            "\n",
            "Starting Needle In A Haystack Testing...\n",
            "- Model: speakleash/Bielik-11B-v2.2-Instruct-GPTQ\n",
            "- Context Lengths: 1, Min: 32768, Max: 32768\n",
            "- Document Depths: 20, Min: 0%, Max: 100%\n",
            "- Needle: The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.\n",
            "\n",
            "\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 54.6 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 16%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 54.4 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 21%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.4 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 26%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.6 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 32%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.7 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 37%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.7 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 42%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.7 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 47%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.7 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 53%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.7 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 58%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.6 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 63%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.6 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 68%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.5 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 74%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.1 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 79%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.5 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 84%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.4 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 89%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.4 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 95%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n",
            "/content/venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "-- Test Summary -- \n",
            "Duration: 55.4 seconds\n",
            "Context: 32768 tokens\n",
            "Depth: 100%\n",
            "Score: 10\n",
            "Response: {'text': 'The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.'}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "%%shell\n",
        "source venv/bin/activate\n",
        "needlehaystack.run_test --provider huggingface --model_name \"speakleash/Bielik-11B-v2.2-Instruct-GPTQ\" --context_lengths \"[32768]\" --document_depth_percent_intervals 20"
      ]
    }
  ]
}